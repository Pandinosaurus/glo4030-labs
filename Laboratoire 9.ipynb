{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rappel Google Colab\n",
    "\n",
    "Tout d'abord, sélectionnez l'option GPU de Colab avec *Edit > Notebook settings* et sélectionner GPU comme Hardware accelerator. \n",
    "Installer ensuite deeplib avec la commande suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ulaval-damas/glo4030-labs.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 9: MLOps - Introduction aux librairies `PyTorch Lightning` et `Weights & Biases`\n",
    "\n",
    "Dans les laboratoires du cours, nous utilisons habituellement les librairies `deeplib` et `Poutyne`, qui offrent beaucoup de fonctionnalités pertinentes au développement et à l'analyse de réseaux de neurones. Dans ce laboratoire, nous allons introduire différents outils très utiles pour le développement et la gestion de projets plus complexes, notamment les travaux pratiques et le projet de session. Nous nous concentrerons sur [`PyTorch Lightning`](https://lightning.ai/docs/pytorch/stable/) (`Lightning`), une librairie qui simplifie grandement l'entraînement et l'évaluation de modèles avec `PyTorch`. Par la suite, nous aurons recours à [`Weights & Biases`](https://docs.wandb.ai/) (`WandB`) pour la recherche d'hyperparamètres et pour la visualisation des résultats.\n",
    "\n",
    "Vous pouvez voir `Lightning` comme une version plus complète et puissante de `Poutyne` utilisé dans les autres laboratoires du cours. Il permet notamment de :\n",
    "- Simplifier la gestion de données et les boucles d'entraînement;\n",
    "- Utiliser différentes précisions de calcul et multiples GPUs;\n",
    "- Inclure des fonctions modulaires *plug-and-play*, telles que des métriques et des callbacks;\n",
    "- Suivre les entrâinements avec des logs, notamment avec `WandB`.\n",
    "\n",
    "Pour `WandB`, nous verrons seulement la recherche d'hyperparamètres et la visualisation, mais vous pouvez regarder la [documentation](https://docs.wandb.ai) pour en savoir plus sur toutes les autres fonctionnalités.\n",
    "\n",
    "Ce laboratoire se veut une introduction aux différents outils souvent utilisés dans la phase de développement du MLOps. Le MLOps reste toutefois beaucoup plus complexe que seulement la partie du développement. Nous pouvons voir le MLOps comme étant un pipeline de développement itératif découpé en 3 phases : \n",
    "- ML : développement de modèles et préparation de jeux de données;\n",
    "- DEV : entraînement, expérimentation et optimisation de modèles;\n",
    "- OPS : déploiement, inférence et exploitation de modèles.\n",
    "\n",
    "Dans le laboratoire, nous allons résoudre une tâche de classification sur le jeu de données `CIFAR-10`, comme dans les autres laboratoires, mais en utilisant `Lightning` et `WandB` au lieu de `deeplib` et `Poutyne`.\n",
    "\n",
    "Nous nous trouvons ici dans la phase DEV, comme nous utiliserons des modèles et des données déjà préparées dans la phase ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from torchvision.models import ResNet18_Weights, resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un compte `Weights & Biases`\n",
    "\n",
    "La première étape du laboratoire est de se créer un compte sur `WandB`. Vous pouvez cliquer sur ce [lien](https://wandb.ai). Pour avoir un abonnement gratuit pour étudiant, il suffit de faire une demande [ici](https://wandb.ai/site/research/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de notre module de données `Lightning`\n",
    "\n",
    "La première étape a réaliser avant même d'entraîner un modèle est d'importer nos données.\n",
    "\n",
    "Jusqu'ici, le téléchargement des données était toujours fait par `deeplib`. `Lightning` offre une classe [`LightningDataModule`](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) qui permet de bien structurer le téléchargement des données jusqu'à la création de `Dataloaders`. Voyons comment nous créons un module de données `Lightning`.\n",
    "\n",
    "Le code est commenté pour permettre de bien suivre les différentes étapes de création d'un module de données `Lightning`. N'hésitez pas à visiter la [documentation](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) pour en savoir plus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous utilisons le même emplacement que deeplib pour éviter de retélécharger inutilement\n",
    "from deeplib.datasets import BASE_PATH\n",
    "\n",
    "base_cifar10_path = os.path.join(BASE_PATH, \"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous créons ici un DataModule Lightning pour le jeu de données CIFAR-10\n",
    "\n",
    "\n",
    "class Cifar10DataModule(L.LightningDataModule):\n",
    "    \"\"\"\n",
    "    DataModule pour le jeu de données CIFAR-10.\n",
    "    Paramètres:\n",
    "        path (str): Répertoire où les données seront stockées.\n",
    "        batch_size (int): Taille de la batch.\n",
    "        val_split (float): Fraction des données d'entraînement à utiliser pour la validation.\n",
    "        num_workers (int): Nombre de workers pour le chargement des données.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path=base_cifar10_path,\n",
    "        batch_size=128,\n",
    "        val_split=0.1,\n",
    "        num_workers=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_dir = path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.val_split = val_split\n",
    "\n",
    "        # Un transformation qui convertit automatiquement différents formats d'entrée (e.g., PIL, numpy) en tensor normalisée entre [0, 1].\n",
    "        # Avec T.Compose, vous pourriez combiner avec diverses augmentations de données afin de bonifier l'entraînement!\n",
    "        self.transform = T.ToTensor()\n",
    "\n",
    "    # Téléchargement des données, appelé sur un seul coeur CPU pour éviter les conflits.\n",
    "    def prepare_data(self):\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    # Configuration des datasets pour l'entraînement, la validation et le test.\n",
    "    # Méthode appelée sur chaque GPU lors d'un entraînement multi-GPU.\n",
    "    def setup(self, stage=None):\n",
    "        full_train = CIFAR10(\n",
    "            self.data_dir, train=True, transform=self.transform, download=False\n",
    "        )\n",
    "        test = CIFAR10(\n",
    "            self.data_dir, train=False, transform=self.transform, download=False\n",
    "        )\n",
    "\n",
    "        num_train = len(full_train)\n",
    "        val_size = int(self.val_split * num_train)\n",
    "        train_size = num_train - val_size\n",
    "        train, val = random_split(full_train, [train_size, val_size])\n",
    "\n",
    "        self.train_dataset = train\n",
    "        self.val_dataset = val\n",
    "        self.test_dataset = test\n",
    "\n",
    "    # Création des DataLoaders pour l'entraînement, la validation et le test.\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            # Évite de réinitialiser les workers à chaque epoch, habituellement plus rapide\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons appeler la fonction `seed_everything`, qui assure la reproductibilité de nos expérimentations.\n",
    "Ça affecte notamment le résultat du `random_split`, `RandomCrop`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(seed=42, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous créons ici un DataModule Lightning pour le jeu de données CIFAR-10\n",
    "cifar10_datamodule = Cifar10DataModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons rapidement que le chargement d'images fonctionne.\n",
    "Nous allons utiliser `torchshow`, une librairie qui simplifie beaucoup le traitement de tensors.\n",
    "Ça prend notamment en compte le format des images, qui sont ici normalisées.\n",
    "Voici la [documentation](https://github.com/xwying/torchshow) pour ceux qui veulent en savoir plus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchshow\n",
    "\n",
    "N_IMAGES = 16\n",
    "N_ROWS = 4\n",
    "\n",
    "# En temps normal, vous n'aurez pas besoin d'appeler ces fonctions\n",
    "cifar10_datamodule.setup()\n",
    "cifar10_test = cifar10_datamodule.test_dataloader()\n",
    "cifar10_train = cifar10_datamodule.train_dataloader()\n",
    "\n",
    "# Chaque itération retourne une batch de 128 images avec leurs labels (voir la définition plus haut)\n",
    "images, labels = next(iter(cifar10_test))\n",
    "torchshow.show(images[:N_IMAGES], nrow=N_ROWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un modèle `Lightning` avec [`LightningModule`](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html)\n",
    "\n",
    "Maintenant que nous avons le `LightningDataModule`, nous pouvons créer un module `Lightning` pour l'entraînement un modèle.\n",
    "Pour simplifier encore plus l'implémentation, nous utiliserons un modèle [`ResNet18` de `torchvision`](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html).\n",
    "Nous visualiserons aussi ce que le préentraînement peut apporter, avec les poids d'un modèle entraîné sur `ImageNet1K`.\n",
    "\n",
    "#### Exercice\n",
    "\n",
    "- Regardez la [documentation sur les logs](https://lightning.ai/docs/pytorch/stable/extensions/logging.html#:~:text=instantiating%20a%20logger.-,Logging%20from%20a%20LightningModule,-Lightning%20offers%20automatic) de `Lightning` et ajouter des logs pour la perte pour: `training_step`, `validation_step` et `test_step`. Pour la perte en entraînement et en validation, ajoutez l'argument `prog_bar=True` afin d'afficher la perte dans la barre de progrès."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningResNet18(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        classes,\n",
    "        lr=0.1,\n",
    "        momentum=0.9,\n",
    "        weight_decay=5e-4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Enregistre tous les paramètres dans self.hparams, et ajoute dans les logs\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Initialise un réseau de neurones préentraîné sur ImageNet1K\n",
    "        self.model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        # Remplace la couche de sortie pour de l'apprentissage par transfert sur CIFAR-10\n",
    "        num_classes = len(classes)\n",
    "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        # Ajout de la fonction de perte\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialisation de l'optimiseur et du scheduler de taux d'apprentissage\n",
    "    def configure_optimizers(self):\n",
    "        # Usage des paramètres enregistrés dans self.hparams\n",
    "        optimizer = torch.optim.SGD(\n",
    "            params=self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            momentum=self.hparams.momentum,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            patience=1,\n",
    "            factor=0.1,\n",
    "        )\n",
    "        scheduler_config = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "        return [optimizer], [scheduler_config]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    # Appelé pour chaque minibatch (step) d'entraînement\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        # TODO: Ajoutez ici un log pour la perte en entraînement, et affichez le résultat sur la barre de progrès\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # Appelé pour chaque minibatch (step) de validation\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        # TODO: Ajoutez ici un log pour la perte en validation, et affichez le résultat sur la barre de progrès\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # Appelé pour chaque minibatch (step) de test\n",
    "    def test_step(self, batch):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        # TODO: Ajoutez ici un log pour la perte en test\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faisons un test rapide pour valider que le module peut être initialisé correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous allons chercher le dictionnaire des classes dans CIFAR-10, qui serviront au logging\n",
    "classes = cifar10_train.dataset.dataset.class_to_idx\n",
    "model = LightningResNet18(classes=classes)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour valider que le module fonctionne correctement, nous pouvons utiliser `torchinfo`.\n",
    "Par exemple, nous pouvons voir la taille des tensors intermédiaires lors du traitement, et estimer la quantité de mémoire nécessaire pour le traitement d'une batch.\n",
    "Ici, nous évaluons pour une batch de 128 images RGB de 224x224 pixels.\n",
    "Pour en savoir plus sur `torchinfo`, vous pouvez visiter la [documentation](https://github.com/TylerYep/torchinfo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "\n",
    "b, c, h, w = 128, 3, 224, 224\n",
    "\n",
    "torchinfo.summary(model, input_size=(b, c, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement avec un `Trainer` de `Lightning`\n",
    "Nous allons maintenant créer un [`Trainer`](https://lightning.ai/docs/pytorch/stable/common/trainer.html), qui gère plusieurs aspects de la boucle d'entraînement et d'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette partie n'est pas importante, et n'est habituellement pas nécessaire\n",
    "# Nous créons une barre de progrès custom pour éviter un bug visuel sur la plateforme ICE\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "\n",
    "\n",
    "class NoValProgressBar(TQDMProgressBar):\n",
    "    def init_validation_tqdm(self):\n",
    "        bar = super().init_validation_tqdm()\n",
    "        bar.disable = True\n",
    "        return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    # En spécifiant \"gpu\" à l'argument accelerator, nous pouvons entraîner sur GPU.\n",
    "    # En arrière plan, les transferts de données sur GPU sont gérées de manière automatique.\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    # Si plusieurs GPU sont disponibles, nous pouvons simplement remplacer \"auto\" par le nombre de GPU.\n",
    "    # Le code sera alors exécuté sur tous les GPU disponibles sans besoin de modifier le reste du code.\n",
    "    devices=\"auto\",\n",
    "    # Le nombre maximal d'epochs pour l'entraînement\n",
    "    max_epochs=5,\n",
    "    # Nous allons revenir sur les callbacks plus loin\n",
    "    callbacks=[NoValProgressBar()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validons que la boucle d'entraînement fonctionne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction gère les boucles d'entraînement et de validation\n",
    "trainer.fit(model, datamodule=cifar10_datamodule)\n",
    "# Cette fonction va chercher le modèle utilisé lors du fit, et gère la boucle de test\n",
    "trainer.test(model, datamodule=cifar10_datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez trouver un nouveau dossier `lightning_logs` dans le répertoire de laboratoires.\n",
    "Ce dossier contient la liste d'hyperparamètres, les métriques et le plus dernier checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Weights & Biases`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procédons maintenant à l'ajout d'un logger `WandB`, qui nous permettra de suivre et visualiser nos entraînements en temps réel.\n",
    "\n",
    "La première étape est de vous connecter avec votre compte `WandB`.\n",
    "Choissisez l'option *Use an existing W&B account*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutons maintenant un `WandbLogger` au `Trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "logger = WandbLogger(project=\"glo4030-labo9\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=\"auto\",\n",
    "    max_epochs=20,\n",
    "    # Notre logger WandB\n",
    "    logger=logger,\n",
    "    callbacks=[NoValProgressBar()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(seed=42, verbose=False)\n",
    "\n",
    "model = LightningResNet18(classes=classes)\n",
    "\n",
    "trainer.fit(model, datamodule=cifar10_datamodule)\n",
    "trainer.test(model, datamodule=cifar10_datamodule)\n",
    "\n",
    "# Nous appelons cette fonction pour indiquer que l'entraînement est terminé et assurer la sauvegarde des résultats\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant visualiser les métriques de l'entraînement et l'évaluation sur le site de `WandB`.\n",
    "Le lien est habituellement indiqué avant et après l'entraînement, mais sinon vous pouvez trouver dans votre projet `glo4030-labo9` sur le site de [WandB](https://wandb.ai).\n",
    "\n",
    "Nous vous invitons à visiter les différents onglets (e.g., train, val, test, System), et à ouvrir l'onglet `Overview` (cliquer sur l'entraînement, puis sur le deuxième onglet en haut) pour comprendre la disposition des informations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Torchmetrics`\n",
    "Bien que la perte (loss) soit utile, nous voudrions des métriques plus fiables et concrètes pour évaluer la performance.\n",
    "Pour cela, nous utiliserons `torchmetrics`, qui regroupe de nombreuses métriques allant de la classification à la détection d'objets.\n",
    "Vous pouvez voir les différentes métriques disponible en suivent ce [lien](https://lightning.ai/docs/torchmetrics/stable/) vers la documentation.\n",
    "\n",
    "Ajoutons par exemple l'accuracy. Nous ajouterons l'accuracy moyenne et celle par classe.\n",
    "\n",
    "Pour ce faire, nous avons besoin de créer un nouveau module `Lightning`.\n",
    "Les parties modifiées du module sont commentées pour votre compréhension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningResNet18(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        classes,\n",
    "        lr=0.1,\n",
    "        momentum=0.9,\n",
    "        weight_decay=5e-4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.classes = classes\n",
    "        self.num_classes = len(classes)\n",
    "\n",
    "        self.model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, self.num_classes)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # Nous devons initialiser une métrique par ensemble de données, puisque les résultats sont accumulés lors de chaque batch\n",
    "        # Nous avons plusieurs classes, alors nous spécifions task=\"multiclass\" et le nombre de classes\n",
    "        self.train_acc = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=self.num_classes\n",
    "        )\n",
    "        self.val_acc = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=self.num_classes\n",
    "        )\n",
    "        self.test_acc = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=self.num_classes\n",
    "        )\n",
    "\n",
    "        # Par défaut, la métrique calcule la moyenne sur toutes les données (micro average)\n",
    "        # Ajoutons également une mesure de la performance par classe\n",
    "        # Puisque c'est plus lourd à calculer, nous allons uniquement l'ajouter en évaluation\n",
    "        self.val_acc_class = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=self.num_classes, average=\"none\"\n",
    "        )\n",
    "        self.test_acc_class = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=self.num_classes, average=\"none\"\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(\n",
    "            params=self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            momentum=self.hparams.momentum,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            patience=1,\n",
    "            factor=0.1,\n",
    "        )\n",
    "        scheduler_config = {\n",
    "            \"scheduler\": scheduler,\n",
    "            # Nous changeons la métrique monitorée par val_acc, puisque ça représente mieux la performance réelle\n",
    "            \"monitor\": \"val_acc\",\n",
    "        }\n",
    "        return [optimizer], [scheduler_config]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        # Il y a plusieurs approches pour calculer et enregistrer les métriques\n",
    "        # Ici, nous appelons update pour calculer les résultats pour la minibatch actuelle\n",
    "        # Lorsque nous appelons log avec `on_epoch`, torchmetrics s'occupe d'accumuler les résultats pour l'epoch complète\n",
    "        self.train_acc.update(outputs, labels)\n",
    "        self.log(\n",
    "            \"train_acc\", self.train_acc, prog_bar=True, on_step=False, on_epoch=True\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "        self.val_acc.update(outputs, labels)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        # Pour bien sauvegarder les métriques par classe, ça demande un peu de travail à la main\n",
    "        self.val_acc_class.update(outputs, labels)\n",
    "        # Nous allons chercher la liste de résultats\n",
    "        acc_class_results = self.val_acc_class.compute()\n",
    "        for class_name, acc_class_result in zip(\n",
    "            self.hparams.classes, acc_class_results\n",
    "        ):\n",
    "            # Nous ajoutons le nom d'une classe à sa métrique respective\n",
    "            # D'ailleurs, nous pouvons ajouter une section avec le format \"<section>/<metric>\"\n",
    "            # Ça permet de séparer les métriques par classe, autrement ça peut être lourd à visualiser\n",
    "            self.log(\n",
    "                f\"val_per_class/acc_{class_name}\",\n",
    "                acc_class_result,\n",
    "                on_step=False,\n",
    "                on_epoch=True,\n",
    "            )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "        self.test_acc.update(outputs, labels)\n",
    "        self.log(\"test_acc\", self.test_acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        # Même chose qu'en val, avec les métriques respectives\n",
    "        self.test_acc_class.update(outputs, labels)\n",
    "        acc_class_results = self.test_acc_class.compute()\n",
    "        for class_name, acc_class_result in zip(\n",
    "            self.hparams.classes, acc_class_results\n",
    "        ):\n",
    "            self.log(\n",
    "                f\"test_per_class/acc_{class_name}\",\n",
    "                acc_class_result,\n",
    "                on_step=False,\n",
    "                on_epoch=True,\n",
    "            )\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectuons un entraînement avec ce mouveau module pour visualiser l'accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(seed=42, verbose=False)\n",
    "\n",
    "logger = WandbLogger(project=\"glo4030-labo9\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=\"auto\",\n",
    "    max_epochs=20,\n",
    "    logger=logger,\n",
    "    callbacks=[NoValProgressBar()],\n",
    ")\n",
    "\n",
    "model = LightningResNet18(classes=classes)\n",
    "\n",
    "trainer.fit(model, datamodule=cifar10_datamodule)\n",
    "trainer.test(model, datamodule=cifar10_datamodule)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenez le temps de regarder les résultats sur `WandB`. Vous devriez observer que la performance n'est pas égale pour toutes les classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Callbacks`\n",
    "Vous devriez remarquer que val_acc ne s'améliore pas lors des dernières epochs. Pour ajouter du early stopping, ainsi que d'autres fonctions utilitaires, nous pouvons utiliser des `Callbacks`. Plusieurs `Callbacks` existent; vous pouvez trouver plus d'informations sur ceux-ci dans la [documentation](https://lightning.ai/docs/pytorch/stable/extensions/callbacks.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(seed=42, verbose=False)\n",
    "\n",
    "logger = WandbLogger(project=\"glo4030-labo9\")\n",
    "\n",
    "# Nous ajoutons quelques Callbacks, des fonctions qui sont appelées périodiquement lors de l'entraînement\n",
    "from lightning.pytorch.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    # Arrêter l'entraînement après X epochs sans amélioration d'un delta Y\n",
    "    EarlyStopping(\n",
    "        # La métrique que nous monitorons\n",
    "        monitor=\"val_acc\",\n",
    "        # L'amélioration minimal pour continuer\n",
    "        min_delta=0.01,\n",
    "        # Le nombre d'epochs à attendre pour une amélioration\n",
    "        patience=5,\n",
    "        # Nous voulons maximiser la métrique que nous monitorons\n",
    "        mode=\"max\",\n",
    "    ),\n",
    "    # Enregistrer le taux d'apprentissage lors de l'entraînement\n",
    "    LearningRateMonitor(),\n",
    "    # Sauvegarder le meilleur checkpoint plutôt que celui de la dernière epoch\n",
    "    ModelCheckpoint(\n",
    "        # Nous pouvons inclure certaines informations dans le nom du checkpoint\n",
    "        filename=\"resnet18-cifar10-{epoch:04d}-{val_acc:.4f}\",\n",
    "        monitor=\"val_acc\",\n",
    "        mode=\"max\",\n",
    "    ),\n",
    "    NoValProgressBar(),\n",
    "]\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=\"auto\",\n",
    "    max_epochs=20,\n",
    "    logger=logger,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model = LightningResNet18(classes=classes)\n",
    "\n",
    "trainer.fit(model, datamodule=cifar10_datamodule)\n",
    "# Nous pouvons spécifier de tester sur le meilleur checkpoint\n",
    "trainer.test(model, datamodule=cifar10_datamodule, ckpt_path=\"best\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez valider que l'entraînement a arrêté préemptivement, et que le checkpoint (qui se trouve dans le dossier de la run, par exemple glo4030-labo9/<run_id>) contient les informations que nous voulions.\n",
    "\n",
    "Vous trouvez peut-être que l'entraînement est rapide, mais rappelez-vous que nous traitons actuellement un projet simple.\n",
    "Pour de grands projets d'apprentissage profond, les entraînements peuvent prendre plusieurs heures, voire plusieurs jours!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les différentes précisions\n",
    "Pour accélérer l'entraînement et l'inférence, nous pouvons modifier la précision des calculs utilisée par `PyTorch`.\n",
    "Nous vous invitons fortement à lire [cette section](https://en.wikipedia.org/wiki/Bfloat16_floating-point_format#bfloat16_floating-point_format) de la page Wikipedia sur le format bfloat16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- Quel est l'avantage d'utiliser un format de précision avec plus, ou moins, de bits?\n",
    "- Pouvez-vous penser à quelques opérations qui ne se traduiraient pas bien en plus basse précision?\n",
    "- Comment se distinguent le format float16 et bfloat16? Comparez-les avec IEEE 754 float32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Lightning` offre deux types de formats de précision, `mixed` et `true`.\n",
    "Les formats `mixed` vont dynamiquement convertir les poids, qui sont stockées en float32, dans le format approprié.\n",
    "Par exemple, les multiplications matricielles seront calculées en basse précision, alors que l'opération softmax aura toujours lieu en haute précision.\n",
    "En comparaison, les formats `true` vont convertir les poids, et toutes les opérations auront lieu à basse précision.\n",
    "\n",
    "Comparons la vitesse de calcul et la performance pour les formats float32 (qui est utilisé par défaut), float16 et bfloat16, pour `mixed` et `true`.\n",
    "Pour cela, nous allons spécifier un argument au `Trainer` de `Lightning`.\n",
    "Vous pouvez trouver la documentation [ici](https://lightning.ai/docs/pytorch/stable/common/precision_basic.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Les sorties sont cachées (puisqu'il y en a beaucoup), allez voir les résultats sur WandB\n",
    "\n",
    "for precision in [\"32-true\", \"16-true\", \"16-mixed\", \"bf16-true\", \"bf16-mixed\"]:\n",
    "    L.seed_everything(seed=42, verbose=False)\n",
    "\n",
    "    logger = WandbLogger(project=\"glo4030-labo9\")\n",
    "\n",
    "    # Un batch size de 128 est assez petit pour les données que nous traitons\n",
    "    # Nous augmentons le batch size pour mieux percevoir la différence entre les précisions\n",
    "    cifar10_datamodule = Cifar10DataModule(batch_size=4096)\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        devices=\"auto\",\n",
    "        max_epochs=20,\n",
    "        logger=logger,\n",
    "        # Nous spécifions la précision\n",
    "        precision=precision,\n",
    "        # Les sorties ne sont pas nécessaires ici\n",
    "        enable_model_summary=False,\n",
    "        enable_checkpointing=False,\n",
    "    )\n",
    "\n",
    "    model = LightningResNet18(classes=classes)\n",
    "\n",
    "    trainer.fit(model, datamodule=cifar10_datamodule)\n",
    "    trainer.test(model, datamodule=cifar10_datamodule)\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- Observez-vous une différence dans le temps de calcul et la consommation de mémoire GPU des entraînements? Si oui, quelles précisions sont les meilleures?\n",
    "**Indice**: Les différences peuvent être très petites; allez sur `WandB` pour voir le temps d'entraînement exact. Pour la consommation mémoire, allez voir l'onglet *GPU Memory Allocated (%)* dans la catégorie `System`.\n",
    "- Le format 32-true devrait offrir la meilleure performance.\n",
    "Quel format s'en rapproche le plus, et pourquoi?\n",
    "**Note**: Pour un problème simple comme celui-ci, c'est plus dur à voir.\n",
    "Fiez-vous à la valeur initiale des courbes de perte en entraînement en tant qu'indicateur de la \"confusion\" du modèle.\n",
    "Vous pouvez également réduire la taille de minibatch à 128 pour mieux voir l'impact de la précision sur la perte.\n",
    "**Indice**: Nous effectuons de l'apprentissage par transfert sur un modèle préentrainé à une précision de 32-true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'impact du format de précision sur le temps d'exécution et la consommation en mémoire GPU dépend sur plusieurs facteurs, dont la carte graphique et la version de CUDA.\n",
    "Dans le cadre du cours, nous recommandons de choisir entre 32-true, 16-mixed et bf16-mixed, mais n'hésitez pas à expérimenter!\n",
    "\n",
    "Notez que vous pouvez également modifier la précision des multiplications matricielles en float32 avec `torch.set_float32_matmul_precision`.\n",
    "Vous pouvez trouver la documentation [ici](https://docs.pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche d'hyperparamètre avec un `WandB` Sweep\n",
    "\n",
    "Jusqu'ici dans le laboratoire, une introduction aux librairies `Lightning` et `WandB` a été effctuée. Toutefois, une grande force de `WandB` n'a toujours pas été explorée, celle de la recherche d'hyperparamètres. \n",
    "\n",
    "Les prochaines cellules vous montrerons comment peut être effectuée le recherche d'hyperparamètre sur `WandB`. Nous vous invitons à prendre le temps de visualiser les différents graphiques générées par `WandB` pour la sweep. Sur la page pour le projet, vous pouvez cliquer sur le bouton `Sweeps` dans la barre de gauche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définissons les hyperparamètres pour WandB\n",
    "# Vous pouvez vous amuser et modifier les différentes valeurs proposées, ou en ajouter!\n",
    "\n",
    "sweep_config = {\n",
    "    # Nous utilisons la recherche bayésienne pour optimiser le choix des hyperparamètres à évaluer\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"values\": [16, 32, 64, 128, 256]},\n",
    "        # Les bonnes valeurs sont souvent réparties sur plusieurs ordres de grandeur.\n",
    "        # Nous utilisons donc une distribution log-uniforme pour le taux d'apprentissage et le weight decay\n",
    "        \"lr\": {\n",
    "            # Attention, log_uniform_values n'est pas équivalent à log_uniform!\n",
    "            \"distribution\": \"log_uniform_values\",\n",
    "            \"min\": 0.0001,\n",
    "            \"max\": 0.1,\n",
    "        },\n",
    "        \"weight_decay\": {\n",
    "            \"distribution\": \"log_uniform_values\",\n",
    "            \"min\": 0.00001,\n",
    "            \"max\": 0.001,\n",
    "        },\n",
    "        \"momentum\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.0,\n",
    "            \"max\": 1.0,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrairement à l'entraînement simple fait plus tôt dans le laboratoire, au lieu d'initialiser un logger `Lightning`, nous allons créer directement une sweep avec la librairie `wandb`.\n",
    "\n",
    "La sweep sera créé dans la prochaine cellule. Pour lancer des entraînement, il suffit de lancer un ou des `Agents`, qui vont choisir les hyperparamètres à évaluer lors de chaque entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"glo4030-labo9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre agent a besoin d'une fonction à exécuter. La cellule suivante montre donc un exemple de fonction pour entraîner un modèle `ResNet18` sur les données `CIFAR-10`. Le code est commenté pour bien expliquer les différentes étapes, mais vous devriez remarquer que ce n'est pas beaucoup plus compliqué que de réaliser un entraînement simple comme fait plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_train():\n",
    "    L.seed_everything(seed=42, verbose=False)\n",
    "\n",
    "    # Initialisation du logger WandB\n",
    "    # Pas besoin d'ajouter un projet ici, car nous sommes dans un sweep\n",
    "    logger = WandbLogger()\n",
    "\n",
    "    # Nous récupérons la configuration des hyperparamètres du sweep\n",
    "    config = logger.experiment.config\n",
    "\n",
    "    # Création du DataModule avec le batch size du sweep\n",
    "    cifar10_datamodule = Cifar10DataModule(batch_size=config.batch_size)\n",
    "\n",
    "    # Création des différents callbacks, comme vu précédemment\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_acc\",\n",
    "            min_delta=0.01,\n",
    "            patience=5,\n",
    "            mode=\"max\",\n",
    "        ),\n",
    "        LearningRateMonitor(),\n",
    "        NoValProgressBar(),\n",
    "    ]\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        devices=\"auto\",\n",
    "        max_epochs=20,\n",
    "        logger=logger,\n",
    "        # Nous avons vu plus haut que la précision bf16-mixed est habituellement un bon choix\n",
    "        precision=\"bf16-mixed\",\n",
    "        callbacks=callbacks,\n",
    "        # Les sorties ne sont pas nécessaires ici\n",
    "        enable_model_summary=False,\n",
    "        enable_checkpointing=False,\n",
    "    )\n",
    "\n",
    "    # Création du modèle\n",
    "    model = LightningResNet18(\n",
    "        classes=classes,\n",
    "        lr=config.lr,\n",
    "        momentum=config.momentum,\n",
    "        weight_decay=config.weight_decay,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=cifar10_datamodule)\n",
    "    trainer.test(model, datamodule=cifar10_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Les sorties sont cachées (puisqu'il y en a beaucoup), allez voir les résultats sur WandB\n",
    "\n",
    "\n",
    "wandb.agent(sweep_id, function=sweep_train, count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "- Quel hyperparamètre a le plus gros impact sur la précision en validation? Quelle est la valeur ou la plage de valeurs qui fonctionne le mieux pour ce paramètre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PyTorch Lightning` et `Weights & Biases` offrent de nombreuses autres fonctionnalités que nous n'allons pas approfondir dans ce laboratoire. Nous vous invitons fortement à lire la documentation, à regarder certains exemples d'usage et à utiliser ces outils pour le projet de session!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
